# Qwen-VL-Med-SFT
![Qwen-VL-Med-SFT æµç¨‹](flowchart0.png)
ä¸€ä¸ªåŸºäº Qwen2-VL ç³»åˆ—æ¨¡å‹çš„åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹å¾®è°ƒæ¡†æ¶ï¼Œä¸“é—¨é’ˆå¯¹ç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„å¤šæ¨¡æ€ä»»åŠ¡è¿›è¡Œä¼˜åŒ–ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®åŸºäº [2U1/Qwen2-VL-Finetune](https://github.com/2U1/Qwen2-VL-Finetune) æ¶æ„ï¼Œä½¿ç”¨ HuggingFace Transformers å’Œ DeepSpeed è¿›è¡Œè®­ç»ƒã€‚åœ¨åŸæœ‰åŸºç¡€ä¸Šå¢å¼ºäº†ä»¥ä¸‹åŠŸèƒ½ï¼š

- âœ… è®­ç»ƒè¿‡ç¨‹ä¸­çš„éªŒè¯æ¨¡å—
- âœ… æ•°æ®é¢„å¤„ç†æ£€æŸ¥
- âœ… æ¨¡å‹æ•ˆæœéªŒè¯
- âœ… ç»“æœç»Ÿè®¡å¯¹æ¯”åˆ†æ

é¡¹ç›®é‡‡ç”¨ [LLaVA-Med](https://github.com/microsoft/LLaVA-Med) æ•°æ®é›†ï¼Œå®ç°ä¸¤é˜¶æ®µå¾®è°ƒç­–ç•¥ï¼š**æ¦‚å¿µå¯¹é½**ï¼ˆConcept Alignmentï¼‰å’Œ**æŒ‡ä»¤è·Ÿéš**ï¼ˆInstruction Followingï¼‰ã€‚

## ğŸ“Š æ•°æ®é¢„å¤„ç†æµç¨‹

### è®­ç»ƒæ•°æ®å¤„ç†

1. **æ•°æ®æ ¼å¼è½¬æ¢**
   - å‚è€ƒ [2U1/Qwen2-VL-Finetune](https://github.com/2U1/Qwen2-VL-Finetune) ç”Ÿæˆæ ‡å‡† JSON æ–‡ä»¶
   - æŒ‰ç…§ DataLoader çš„æ•°æ®å¤„ç†æ–¹å¼è¿›è¡Œè¿­ä»£éªŒè¯ï¼Œç­›é€‰æœ‰æ•ˆæ•°æ®

2. **éªŒè¯æ•°æ®å¤„ç†**
   - ä½¿ç”¨ `./data_process/data_trans.py` è„šæœ¬å¤„ç†
   - ç”Ÿæˆ `test.json` å’Œ `type_mapping.json` ç”¨äºæµ‹è¯•å’Œåˆ†ç±»

### æ•°æ®åˆ†ç±»ä½“ç³»

æ ¹æ®é—®é¢˜ç±»å‹ï¼Œæˆ‘ä»¬å°†æ•°æ®åˆ†ä¸ºä»¥ä¸‹ç±»åˆ«ï¼š

#### å°é—­å¼é—®é¢˜ï¼ˆClose-setï¼‰

| ç±»å‹ | ä»»åŠ¡æè¿° |
|------|----------|
| **Yes/No åˆ¤æ–­** | å¯¹åŒ»å­¦å½±åƒä¸­ç‰¹å®šç‰¹å¾æˆ–å¼‚å¸¸çš„å­˜åœ¨æ€§è¿›è¡ŒäºŒå…ƒåˆ¤æ–­ |
| **æ¨¡æ€è¯†åˆ«** | è¯†åˆ«åŒ»å­¦å½±åƒçš„æˆåƒæ–¹å¼æˆ–æŠ€æœ¯ç±»å‹ |
| **é€šç”¨é—®é¢˜** | ä¸å±äºç‰¹å®šç±»åˆ«çš„å°é—­å¼é—®é¢˜ |
| **ä½ç½®å®šä½** | è¯¢é—®ç—…å˜æˆ–ç»“æ„çš„å…·ä½“ä½ç½®ï¼ˆé™å®šé€‰é¡¹ï¼‰ |

#### å¼€æ”¾å¼é—®é¢˜ï¼ˆOpen-endï¼‰

| ç±»å‹ | ä»»åŠ¡æè¿° |
|------|----------|
| **é€šç”¨æè¿°** | éœ€è¦ç»¼åˆæè¿°æˆ–è§£é‡Šçš„å¼€æ”¾æ€§é—®é¢˜ |
| **è§£å‰–è¯†åˆ«** | è¯†åˆ«å’Œæè¿°å½±åƒä¸­çš„è§£å‰–ç»“æ„æˆ–å™¨å®˜ |
| **ä½ç½®æè¿°** | è¯¦ç»†æè¿°ç—…å˜æˆ–ç»“æ„çš„ä½ç½® |
| **å¼‚å¸¸è¯†åˆ«** | è¯†åˆ«å’Œæè¿°ç—…ç†æ”¹å˜æˆ–å¼‚å¸¸å‘ç° |
| **è®¡æ•°ä»»åŠ¡** | è®¡ç®—å½±åƒä¸­ç‰¹å®šå¯¹è±¡çš„æ•°é‡ |
| **æ¯”è¾ƒåˆ†æ** | æ¯”è¾ƒä¸åŒç»“æ„æˆ–æ—¶é—´ç‚¹çš„å˜åŒ– |
| **å¤–è§‚æè¿°** | æè¿°ç—…å˜æˆ–ç»“æ„çš„è§†è§‰ç‰¹å¾ |
| **å½±å“è¯„ä¼°** | è¯„ä¼°ç—…å˜å¯¹å‘¨å›´ç»“æ„çš„å½±å“ |

## ğŸš€ æ¨¡å‹è®­ç»ƒ

### è®­ç»ƒæ¶æ„

åŸºäº HuggingFace Transformers çš„ `Trainer` ç±»è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡ `trainer.add_callback(callback)` æ–¹å¼é›†æˆï¼š
- éªŒè¯æµç¨‹å›è°ƒ
- TensorBoard æ—¥å¿—è®°å½•
- è®­ç»ƒè¿‡ç¨‹ç›‘æ§

### å¯åŠ¨è®­ç»ƒ

#### å•å¡è®­ç»ƒ/è°ƒè¯•
```bash
bash finetune_lora_single_gpu.sh
```

#### å¤šå¡è®­ç»ƒï¼ˆDeepSpeedï¼‰
```bash
bash finetune_lora_mult_gpu.sh
```

## ğŸ§ª æ¨¡å‹æµ‹è¯•ä¸è¯„ä¼°

### æµ‹è¯•é…ç½®

æ”¯æŒä¸¤ç§æµ‹è¯•æ¨¡å¼ï¼š
- **è‡ªå®šä¹‰ Prompt æµ‹è¯•**ï¼šä½¿ç”¨è‡ªè®¾å®šçš„æç¤ºè¯
- **åŸå§‹ System Prompt æµ‹è¯•**ï¼šä½¿ç”¨æ¨¡å‹é»˜è®¤æç¤ºè¯

æµ‹è¯•è¿‡ç¨‹ä¼šè®¡ç®—å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ï¼Œå¹¶å¯¹æ¯”åŸºç¡€æ¨¡å‹å’Œ LoRA æ¨¡å‹çš„ç»“æœã€‚

### å¯åŠ¨æµ‹è¯•
```bash
bash run_eval.sh
```

### ç»“æœç»Ÿè®¡åˆ†æ

ä½¿ç”¨ `result_statistic.py` è„šæœ¬è¿›è¡Œåˆ†ç±»åˆ«ç»Ÿè®¡åˆ†æã€‚

#### è¯„ä¼°æŒ‡æ ‡ä½“ç³»

| æŒ‡æ ‡åç§° | å€¼åŸŸèŒƒå›´ | åˆç†åˆ†æ•°åŒºé—´ | å«ä¹‰è§£é‡Š | è¯´æ˜ |
|----------|----------|--------------|----------|------|
| **BLEU-4** | 0 ~ 1 | 0.2 ~ 0.6 | n-gram ç²¾ç¡®åŒ¹é…ç‡ | è¡¡é‡å±€éƒ¨è¯­è¨€åŒ¹é…ï¼Œæƒ©ç½šé‡å¤ã€ç¼ºè¯ |
| **ROUGE-L** | 0 ~ 1 | 0.3 ~ 0.6 | æœ€é•¿å…¬å…±å­åºåˆ—çš„å¬å›ç‡ | é‡è§†ä¿¡æ¯è¦†ç›–ï¼Œåå‘å¬å›ç‡ |
| **METEOR** | 0 ~ 1 | 0.3 ~ 0.5 | ç²¾ç¡®åº¦ + å¬å› + è¯­ä¹‰åŒä¹‰è¯ + è¯åºæƒ©ç½šç»¼åˆæŒ‡æ ‡ | å®½å®¹è¡¨è¾¾å·®å¼‚ï¼Œé€‚åˆç”Ÿæˆå¼ä»»åŠ¡ |
| **CIDEr** | 0 ~ âˆ | 0.5 ~ 2.0 | åŸºäº TF-IDF çš„åŠ æƒ n-gram åŒ¹é…è¯„åˆ† | å¤šå‚è€ƒæ—¶é²æ£’ï¼Œå¸¸ç”¨äºå›¾æ–‡ä»»åŠ¡ |
| **BERTScore (F1)** | 0 ~ 1 | 0.85 ~ 0.95 | åŸºäº BERT çš„å¥å‘é‡è¯­ä¹‰ç›¸ä¼¼åº¦ | è¡¨è¾¾çµæ´»æ—¶ä¾æ—§æœ‰æ•ˆ |
| **Soft Matching** | 0 ~ 1 | 0.6 ~ 0.95 | å­—ç¬¦çº§ç›¸ä¼¼åº¦ï¼ˆå¦‚ SequenceMatcher/LCS æ¯”ä¾‹ï¼‰ | æ•æ‰å­—ç¬¦ä¸²çš„éƒ¨åˆ†ç›¸ä¼¼ï¼Œå®¹é”™æ€§å¼º |
| **Substring Match** | 0 æˆ– 1 | äºŒå€¼å‹ï¼ˆ0/1ï¼‰ | æ˜¯å¦å®Œå…¨åŒ…å«ï¼ˆå‚è€ƒ âˆˆ é¢„æµ‹ æˆ–åä¹‹ï¼‰ | éå¸¸ä¸¥æ ¼ï¼Œé€‚ç”¨äºç­”æ¡ˆçŸ­æ˜ç¡®åœºæ™¯ |

### ğŸ“ˆ å®éªŒç»“æœ

#### Qwen2-VL ç”Ÿç‰©åŒ»ç–—é—®ç­”å¾®è°ƒä¸æ€§èƒ½åˆ†æ

*  å¾®è°ƒæ–¹æ¡ˆä¸å®éªŒè®¾ç½®

* æ¦‚å¿µå¯¹é½å¾®è°ƒï¼ˆStage 1ï¼‰
- åŸºäº Qwen2-VL-Instruct 2B ä¸ 7B æ¨¡å‹
- ä½¿ç”¨çº¦ 16 ä¸‡æ¡å¤šæ¨¡æ€å¯¹é½æ•°æ®ï¼Œä¸»è¦é‡‡ç”¨ LoRA æŠ€æœ¯å¾®è°ƒè§†è§‰-è¯­è¨€èåˆæ¨¡å—ï¼ˆvisual-merger-projï¼‰

* Instruct SFT å¾®è°ƒï¼ˆStage 2ï¼‰
- é‡‡ç”¨ LoRA å¾®è°ƒ attention å±‚ FNN éƒ¨åˆ†ï¼Œæå‡ä¿¡æ¯æ•´åˆèƒ½åŠ›
- **æ–¹æ¡ˆ 1**ï¼šåŸºäº LLaVA-Med Instruct æ•°æ®é›†ï¼ˆ16Kï¼‰ï¼Œ3 è½®è®­ç»ƒï¼Œæ˜¾è‘—æå‡å›å¤è´¨é‡ï¼Œå›°æƒ‘åº¦ä¸‹é™ï¼ŒWord F1 æé«˜
- **æ–¹æ¡ˆ 2**ï¼šåŸºäº Slake è®­ç»ƒé›†ï¼ˆçº¦ 5Kï¼‰ï¼Œ3 è½®è®­ç»ƒï¼Œå›å¤é£æ ¼æ›´ç®€æ´ï¼ŒWord F1 æ˜¾è‘—æå‡

- **æµ‹è¯•é›†**ï¼šSlake ç”Ÿç‰©åŒ»å­¦è§†è§‰é—®ç­”æ•°æ®é›†

#### ç»“æœæ€»ç»“

- **æ¦‚å¿µå¯¹é½å¾®è°ƒ**ï¼šæœ‰åŠ©äºè§†è§‰ä¸è¯­è¨€ä¿¡æ¯çš„ä¸“ä¸šé¢†åŸŸå¯¹é½ï¼Œå¢å¼ºæ¨¡å‹åœ¨åŒ»å­¦é—®ç­”ä¸­çš„è¡¨ç°
- **Instruct SFT**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹å›å¤é£æ ¼ä¸è¯­è¨€è¡¨è¾¾
- **æ¨¡å‹å±€é™**ï¼š
  - ç—…å˜ä½ç½®ç¡®è®¤ä¸ç›¸å¯¹ä½ç½®è¡¨è¿°èƒ½åŠ›ä»å¾…æå‡
  - å¯¹éƒ¨åˆ†ç—…ç—‡æœ‰â€œè½»åº¦â€æè¿°å€¾å‘
* è¡¨æ ¼è¯´æ˜ï¼š
| æ¨¡å‹ç®€ç§°                            | è®­ç»ƒæ–¹å¼åŠè¯´æ˜                                                |
| ----------------------------------- | ------------------------------------------------------------ |
| Qwen2VL2BInst_Stage1                | Qwen2-VL-2B instructï¼Œæ¦‚å¿µå¯¹é½å¾®è°ƒ           |
| Qwen2VL7BInst                       | Qwen2-VL-7B instructï¼Œæ— å¾®è°ƒ                   |
| Qwen2VL7B                           | Qwen2-VL-7B Baseï¼Œæœªç»è¿‡å¾®è°ƒ                      |
| Qwen2VL7BBase_Stage1                | Qwen2-VL-7B Baseï¼Œæ¦‚å¿µå¯¹é½å¾®è°ƒ               |
| Qwen2VL7BInst_Stage1                | Qwen2-VL-7B instructï¼Œæ¦‚å¿µå¯¹é½å¾®è°ƒ        |
| Qwen2VL7BInstSlakeTrainBaseOnStage1 | Qwen2-VL-7B instructï¼Œæ¦‚å¿µå¯¹é½å¾®è°ƒåä»¥ Slake Instruct å¾®è°ƒ |
| Qwen25VL32BInst                     | Qwen2-VL-32B instruct æ— è®­ç»ƒ                   |


#### æ€§èƒ½å¯¹æ¯”
* **æ•´ä½“æ€§èƒ½** 
è¯¦ç»†ç»“æœè§ [`result/model_comparison_tables.txt`](result/model_comparison_tables.txt)ï¼Œ  
ä¸ªä¾‹ç»Ÿè®¡è§ [`result/evaluation_metrics.json`](result/evaluation_metrics.json)
| Category | Metric | Qwen2VL2BInst_Stage1 | Qwen2VL7BInst | Qwen2VL7B | Qwen2VL7BBase_Stage1 | Qwen2VL7BInst_Stage1 | Qwen2VL7BInstSlakeTrainBaseOnStage1 | Qwen25VL32BInst |
|----------|--------|--------|--------|--------|--------|--------|--------|--------|
| Text Matching | Exact Match | 0.2026 | 0.0000 | 0.0000 | 0.1225 | 0.4354 | **0.4722** | 0.0000 |
| Text Matching | Soft Match | 0.3291 | 0.0960 | 0.0139 | 0.2949 | 0.5477 | **0.5791** | 0.0037 |
| Text Matching | ROUGE-L | 0.2796 | 0.0897 | 0.0254 | 0.2669 | 0.4809 | **0.5125** | 0.0156 |
| Text Matching | BLEU-4 | 0.0458 | 0.0082 | 0.0019 | 0.0420 | 0.0845 | **0.0899** | 0.0009 |
| Text Matching | Word Overlap | 0.2513 | 0.0565 | 0.0192 | 0.2107 | 0.4621 | **0.4954** | 0.0125 |
| Text Matching | BERTScore F1 | **0.0000** | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0.0000 |
| Fine-grained | Char F1 | 0.4898 | 0.3525 | 0.3322 | 0.4378 | 0.6094 | **0.6247** | 0.3236 |
| Fine-grained | Word F1 | 0.2844 | 0.0994 | 0.0368 | 0.2607 | 0.4733 | **0.5052** | 0.0244 |
| Fine-grained | Char Precision | 0.4288 | 0.2581 | 0.2400 | 0.3699 | 0.6095 | **0.6370** | 0.2264 |
| Fine-grained | Char Recall | 0.7300 | 0.7999 | 0.7973 | 0.7368 | 0.6523 | 0.6383 | **0.8596** |
| Fine-grained | Word Precision | 0.2551 | 0.0574 | 0.0193 | 0.2173 | 0.4717 | **0.5095** | 0.0125 |
| Fine-grained | Word Recall | 0.4746 | 0.5403 | 0.5565 | 0.5060 | 0.5028 | 0.5154 | **0.6631** |
| Perplexity | Mean Perplexity | 882.7204 | 240741.5970 | 621617.2925 | 798.9098 | 278.8062 | **173.8327** | 694010380428.6918 |

* æ€»ä½“ç»“æœåˆ†æ
- **å°é—­å¼é—®é¢˜**ï¼šLoRA æ¨¡å‹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šéƒ½æœ‰æ˜¾è‘—æå‡ï¼Œç‰¹åˆ«æ˜¯ Word F1 ä» 0.1121 æå‡åˆ° 0.7493
- **å¼€æ”¾å¼é—®é¢˜**ï¼šWord F1 ä» 0.0930 æå‡åˆ° 0.3824
- **æ•´ä½“æ€§èƒ½**ï¼šWord F1 ä» 0.0994 æå‡åˆ° 0.5052ï¼ŒLoRA å¾®è°ƒåæ¨¡å‹åœ¨åŒ»å­¦è§†è§‰é—®ç­”ä»»åŠ¡ä¸Šå±•ç°å‡ºæ›´å¥½çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›

## ğŸ”§ ç¯å¢ƒè¦æ±‚

requirement.txt

## ğŸ“š å‚è€ƒèµ„æ–™

- [2U1/Qwen2-VL-Finetune](https://github.com/2U1/Qwen2-VL-Finetune)
- [Microsoft LLaVA-Med](https://github.com/microsoft/LLaVA-Med)
- [Qwen2-VL å®˜æ–¹æ–‡æ¡£](https://github.com/QwenLM/Qwen2-VL)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªç›¸åº”çš„å¼€æºè®¸å¯è¯ï¼Œè¯·å‚è€ƒå„ä¸ªä¾èµ–é¡¹ç›®çš„è®¸å¯è¯è¦æ±‚ã€‚



# Qwen-VL-Med-SFT

![Qwen-VL-Med-SFT Workflow](flowchart0.png)

A medical vision-language model fine-tuning framework based on the Qwen2-VL series, specifically optimized for biomedical multimodal tasks.

## ğŸ¯ Project Overview

This project is built upon the [2U1/Qwen2-VL-Finetune](https://github.com/2U1/Qwen2-VL-Finetune) architecture, utilizing HuggingFace Transformers and DeepSpeed for training. Enhanced features include:

- âœ… Validation module during training
- âœ… Data preprocessing validation
- âœ… Model effectiveness verification
- âœ… Statistical comparison analysis

The project uses the [LLaVA-Med](https://github.com/microsoft/LLaVA-Med) dataset and implements a two-stage fine-tuning strategy: **Concept Alignment** and **Instruction Following**.

## ğŸ“Š Data Preprocessing Pipeline

### Training Data Processing
1. **Data Format Conversion**
   - Generate standard JSON files following [2U1/Qwen2-VL-Finetune](https://github.com/2U1/Qwen2-VL-Finetune) format
   - Iterative validation according to DataLoader processing to filter valid data

2. **Validation Data Processing**
   - Use `./data_process/data_trans.py` script for processing
   - Generate `test.json` and `type_mapping.json` for testing and classification

### Data Classification System

Based on question types, we categorize data into the following classes:

#### Closed-set Questions
| Type | Task Description |
|------|------------------|
| **Yes/No Judgment** | Binary judgment on the presence of specific features or abnormalities in medical images |
| **Modality Recognition** | Identify imaging modalities or technical types of medical images |
| **General Questions** | Closed-set questions not belonging to specific categories |
| **Location Positioning** | Inquire about specific locations of lesions or structures (limited options) |

#### Open-end Questions
| Type | Task Description |
|------|------------------|
| **General Description** | Open-ended questions requiring comprehensive description or explanation |
| **Anatomical Identification** | Identify and describe anatomical structures or organs in images |
| **Location Description** | Detailed description of lesion or structure locations |
| **Abnormality Recognition** | Identify and describe pathological changes or abnormal findings |
| **Counting Tasks** | Count specific objects in images |
| **Comparative Analysis** | Compare changes across different structures or time points |
| **Appearance Description** | Describe visual characteristics of lesions or structures |
| **Impact Assessment** | Evaluate lesion impact on surrounding structures |

## ğŸš€ Model Training

### Training Architecture
Based on HuggingFace Transformers' `Trainer` class with integrated callbacks via `trainer.add_callback(callback)`:
- Validation workflow callbacks
- TensorBoard logging
- Training process monitoring

### Starting Training

#### Single GPU Training/Debugging
```bash
bash finetune_lora_single_gpu.sh
```

#### Multi-GPU Training (DeepSpeed)
```bash
bash finetune_lora_mult_gpu.sh
```

## ğŸ§ª Model Testing and Evaluation

### Test Configuration
Supports two testing modes:
- **Custom Prompt Testing**: Using custom prompts
- **Original System Prompt Testing**: Using model default prompts

The testing process calculates perplexity and compares results between base and LoRA models.

### Running Tests
```bash
bash run_eval.sh
```

### Statistical Result Analysis
Use the `result_statistic.py` script for category-wise statistical analysis.

#### Evaluation Metrics System
| Metric Name | Value Range | Reasonable Score Range | Meaning | Description |
|-------------|-------------|----------------------|---------|-------------|
| **BLEU-4** | 0 ~ 1 | 0.2 ~ 0.6 | n-gram precision matching rate | Measures local language matching, penalizes repetition and missing words |
| **ROUGE-L** | 0 ~ 1 | 0.3 ~ 0.6 | Longest common subsequence recall | Emphasizes information coverage, favors recall |
| **METEOR** | 0 ~ 1 | 0.3 ~ 0.5 | Comprehensive metric: precision + recall + semantic synonyms + word order penalty | Tolerant of expression differences, suitable for generative tasks |
| **CIDEr** | 0 ~ âˆ | 0.5 ~ 2.0 | TF-IDF weighted n-gram matching score | Robust with multiple references, common in vision-language tasks |
| **BERTScore (F1)** | 0 ~ 1 | 0.85 ~ 0.95 | BERT-based sentence vector semantic similarity | Effective even with flexible expressions |
| **Soft Matching** | 0 ~ 1 | 0.6 ~ 0.95 | Character-level similarity (e.g., SequenceMatcher/LCS ratio) | Captures partial string similarity, strong fault tolerance |
| **Substring Match** | 0 or 1 | Binary (0/1) | Whether completely contained (reference âˆˆ prediction or vice versa) | Very strict, suitable for short and clear answer scenarios |

## ğŸ“ˆ Experimental Results

Based on Qwen2-VL-Instruct with concept alignment fine-tuning, applying LoRA technique to the visual-merger-proj module. Comparison results available in: `result/evaluation_metrics.json`

### Performance Comparison
| Category | Metric | Qwen2VL2BInst_Stage1 | Qwen2VL7BInst | Qwen2VL7B | Qwen2VL7BBase_Stage1 | Qwen2VL7BInst_Stage1 | Qwen2VL7BInst_SlakeTrain_BaseOnStage1 | Qwen25VL32BInst |
|----------|--------|--------|--------|--------|--------|--------|--------|--------|
| Text Matching | Exact Match | 0.4873 | 0.0000 | 0.0000 | 0.2873 | 0.7437 | **0.7493** | 0.0000 |
| Text Matching | Soft Match | 0.5198 | 0.0634 | 0.0154 | 0.3570 | 0.7443 | **0.7495** | 0.0053 |
| Text Matching | ROUGE-L | 0.5366 | 0.1002 | 0.0258 | 0.3834 | 0.7450 | **0.7493** | 0.0134 |
| Text Matching | BLEU-4 | 0.0914 | 0.0093 | 0.0021 | 0.0607 | 0.1324 | **0.1332** | 0.0010 |
| Text Matching | Word Overlap | 0.5167 | 0.0631 | 0.0188 | 0.3467 | 0.7444 | **0.7493** | 0.0109 |
| Fine-grained | Char F1 | 0.5674 | 0.2173 | 0.1875 | 0.4293 | 0.7424 | **0.7481** | 0.1822 |
| Fine-grained | Word F1 | 0.5390 | 0.1121 | 0.0361 | 0.3886 | 0.7451 | **0.7493** | 0.0214 |
| Fine-grained | Char Precision | 0.5349 | 0.1283 | 0.1083 | 0.3722 | 0.7417 | **0.7480** | 0.1052 |
| Fine-grained | Char Recall | 0.7765 | **0.8582** | 0.7798 | 0.8061 | 0.7535 | 0.7493 | 0.8202 |
| Fine-grained | Word Precision | 0.5167 | 0.0631 | 0.0188 | 0.3467 | 0.7444 | **0.7493** | 0.0109 |
| Fine-grained | Word Recall | 0.7296 | 0.6986 | 0.5887 | 0.7014 | **0.7549** | 0.7493 | 0.6620 |

### Key Findings
- **Closed-set Questions**: LoRA model shows significant improvement across all metrics, particularly Exact Match improving from 0.000 to 0.341
- **Open-end Questions**: Although improvements are relatively smaller, notable enhancements in Soft Match and ROUGE-L metrics
- **Overall Performance**: LoRA fine-tuned model demonstrates better understanding and generation capabilities in medical visual question answering tasks

## ğŸ”§ Environment Requirements

See `requirements.txt` for detailed dependencies.

## ğŸ“š References

- [2U1/Qwen2-VL-Finetune](https://github.com/2U1/Qwen2-VL-Finetune)
- [Microsoft LLaVA-Med](https://github.com/microsoft/LLaVA-Med)
- [Qwen2-VL Official Documentation](https://github.com/QwenLM/Qwen2-VL)

## ğŸ“„ License

This project follows the corresponding open-source licenses. Please refer to the license requirements of each dependency project.

---

## ğŸŒ Language Versions

- [English](README.md)
- [ä¸­æ–‡](README_zh.md)
